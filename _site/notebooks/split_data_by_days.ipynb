{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "\n",
    "data_file = 'data/wiki_data.pkl'\n",
    "links_file = 'data/links.tsv'\n",
    "out_dir = 'data/daily_visitors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, read visit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>01/01</th>\n",
       "      <th>02/01</th>\n",
       "      <th>03/01</th>\n",
       "      <th>04/01</th>\n",
       "      <th>05/01</th>\n",
       "      <th>06/01</th>\n",
       "      <th>07/01</th>\n",
       "      <th>08/01</th>\n",
       "      <th>09/01</th>\n",
       "      <th>...</th>\n",
       "      <th>22/12</th>\n",
       "      <th>23/12</th>\n",
       "      <th>24/12</th>\n",
       "      <th>25/12</th>\n",
       "      <th>26/12</th>\n",
       "      <th>27/12</th>\n",
       "      <th>28/12</th>\n",
       "      <th>29/12</th>\n",
       "      <th>30/12</th>\n",
       "      <th>31/12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áedán mac Gabráin</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland</td>\n",
       "      <td>136</td>\n",
       "      <td>184</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>209</td>\n",
       "      <td>168</td>\n",
       "      <td>131</td>\n",
       "      <td>157</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>109</td>\n",
       "      <td>123</td>\n",
       "      <td>112</td>\n",
       "      <td>141</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Édouard Manet</td>\n",
       "      <td>703</td>\n",
       "      <td>895</td>\n",
       "      <td>951</td>\n",
       "      <td>1081</td>\n",
       "      <td>1047</td>\n",
       "      <td>977</td>\n",
       "      <td>984</td>\n",
       "      <td>1121</td>\n",
       "      <td>1221</td>\n",
       "      <td>...</td>\n",
       "      <td>553</td>\n",
       "      <td>643</td>\n",
       "      <td>638</td>\n",
       "      <td>745</td>\n",
       "      <td>793</td>\n",
       "      <td>773</td>\n",
       "      <td>763</td>\n",
       "      <td>725</td>\n",
       "      <td>737</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Éire</td>\n",
       "      <td>320</td>\n",
       "      <td>368</td>\n",
       "      <td>396</td>\n",
       "      <td>378</td>\n",
       "      <td>414</td>\n",
       "      <td>438</td>\n",
       "      <td>354</td>\n",
       "      <td>394</td>\n",
       "      <td>405</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>289</td>\n",
       "      <td>326</td>\n",
       "      <td>372</td>\n",
       "      <td>360</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>368</td>\n",
       "      <td>346</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Óengus I of the Picts</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article  01/01  02/01  03/01  04/01  05/01  06/01  07/01  \\\n",
       "0      Áedán mac Gabráin     35     42     63     46     70     54     43   \n",
       "1                  Åland    136    184    162    163    209    168    131   \n",
       "2          Édouard Manet    703    895    951   1081   1047    977    984   \n",
       "3                   Éire    320    368    396    378    414    438    354   \n",
       "4  Óengus I of the Picts     28     32     22     18     33     18     22   \n",
       "\n",
       "   08/01  09/01  ...    22/12  23/12  24/12  25/12  26/12  27/12  28/12  \\\n",
       "0     48     44  ...       28     38     26     43     54     44     36   \n",
       "1    157    203  ...      110     95     95    109    123    112    141   \n",
       "2   1121   1221  ...      553    643    638    745    793    773    763   \n",
       "3    394    405  ...      364    289    326    372    360    389    389   \n",
       "4     32     25  ...       21     26     12     34     47     26     24   \n",
       "\n",
       "   29/12  30/12  31/12  \n",
       "0     45     29     84  \n",
       "1    135    122     99  \n",
       "2    725    737    630  \n",
       "3    368    346    390  \n",
       "4     23     35     28  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_data(file):\n",
    "    data = pkl.load(open(file, 'rb'))\n",
    "\n",
    "    data = data.drop('categories', axis=1)\n",
    "    traffic = data['traffic']\n",
    "    \n",
    "    # Remove data for which there are not enough days\n",
    "    day_count = traffic.apply(lambda x: len(x))\n",
    "    traffic = traffic[day_count == 365]\n",
    "    \n",
    "    # Separate data by days\n",
    "    day_series = {}\n",
    "    for i in range(365):\n",
    "        day = traffic.iloc[0][i][1].split('-')\n",
    "        day[2] = day[2].split('T')[0]\n",
    "        day = f'{day[2]}/{day[1]}'\n",
    "        day_series[day] = traffic.apply(lambda x: x[i][0])\n",
    "    \n",
    "    # Add visit by day columns to the dataframe\n",
    "    data = data[day_count == 365]\n",
    "    data = pd.concat([data, pd.DataFrame(day_series)], axis=1)\n",
    "    data = data.drop('traffic', axis=1)    \n",
    "    return data\n",
    "\n",
    "\n",
    "visit_data = read_data(data_file)\n",
    "display(visit_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the links between the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read hyperlinks dataset\n",
    "links = pd.read_csv('data/links.tsv', \n",
    "                    sep='\\t', \n",
    "                    encoding='utf-8', \n",
    "                    engine='python', \n",
    "                    header=None, \n",
    "                    comment='#',\n",
    "                    names=['source', 'target'])\n",
    "\n",
    "links['source'] = links['source'].apply(lambda s: urllib.parse.unquote(s))\n",
    "links['target'] = links['target'].apply(lambda s: urllib.parse.unquote(s))\n",
    "\n",
    "display(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29326</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Binoculars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29327</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Clone_Wars_(Star_Wars)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29328</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Darth_Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29329</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Dutch_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29330</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Frankenstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29331</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>German_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29332</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29333</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>King_Arthur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29334</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Natalie_Portman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29335</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Obi-Wan_Kenobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Star_Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Star_Wars_Episode_IV__A_New_Hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Stargate_SG-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Superman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                            target\n",
       "29326  Darth_Vader                        Binoculars\n",
       "29327  Darth_Vader            Clone_Wars_(Star_Wars)\n",
       "29328  Darth_Vader                       Darth_Vader\n",
       "29329  Darth_Vader                    Dutch_language\n",
       "29330  Darth_Vader                      Frankenstein\n",
       "29331  Darth_Vader                   German_language\n",
       "29332  Darth_Vader                             Japan\n",
       "29333  Darth_Vader                       King_Arthur\n",
       "29334  Darth_Vader                   Natalie_Portman\n",
       "29335  Darth_Vader                    Obi-Wan_Kenobi\n",
       "29336  Darth_Vader                         Star_Wars\n",
       "29337  Darth_Vader  Star_Wars_Episode_IV__A_New_Hope\n",
       "29338  Darth_Vader                     Stargate_SG-1\n",
       "29339  Darth_Vader                          Superman"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[links['source'] == 'Darth_Vader']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start generating the data. We will first generate the edges, which are common for all the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mapping between article name and its ID for fast retrieval\n",
    "article_dict = {}\n",
    "for i in range(len(visit_data)):\n",
    "    article_dict[visit_data.iloc[i].article] = f'n{i}'\n",
    "\n",
    "edges = []\n",
    "cnt = 0\n",
    "for i in range(len(links)):\n",
    "    source = links.iloc[i].source.replace('_', ' ')\n",
    "    target = links.iloc[i].target.replace('_', ' ')\n",
    "    if source in article_dict and target in article_dict:\n",
    "        edge = {\n",
    "            'id': f'e{cnt}',\n",
    "            'source': article_dict[source],\n",
    "            'target': article_dict[target],\n",
    "            'type': 'arrow'\n",
    "        }\n",
    "        cnt += 1\n",
    "        edges.append(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the node data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_nodes = defaultdict(list)\n",
    "for i in range(len(visit_data)):\n",
    "    for day in visit_data.columns[1:]:\n",
    "        node = {\n",
    "            'id': article_dict[visit_data.iloc[i].article],\n",
    "            'label': visit_data.iloc[i].article,\n",
    "            'size': visit_data[day].iloc[i]\n",
    "        }\n",
    "        daily_nodes[day].append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the edge and the node data in pickle files\n",
    "pkl.dump(edges, open('data/edges.pkl', 'wb'))\n",
    "pkl.dump(daily_nodes, open('data/nodes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pkl.load(open('data/edges.pkl', 'rb'))\n",
    "nodes = pkl.load(open('data/nodes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116230"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = {\n",
    "    'nodes': nodes['01/01'],\n",
    "    'edges': edges\n",
    "}\n",
    "sample_data['nodes'] = list(map(lambda x: {\n",
    "    'id': x['id'],\n",
    "    'label': x['label'],\n",
    "    'size': int(x['size'])\n",
    "}, sample_data['nodes']))\n",
    "\n",
    "# json.dump(sample_data, open('sample_data.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data01_01.json\n",
      "data01_02.json\n",
      "data01_03.json\n",
      "data01_04.json\n",
      "data01_05.json\n",
      "data01_06.json\n",
      "data01_07.json\n",
      "data01_08.json\n",
      "data01_09.json\n",
      "data01_10.json\n",
      "data01_11.json\n",
      "data01_12.json\n",
      "data02_01.json\n",
      "data02_02.json\n",
      "data02_03.json\n",
      "data02_04.json\n",
      "data02_05.json\n",
      "data02_06.json\n",
      "data02_07.json\n",
      "data02_08.json\n",
      "data02_09.json\n",
      "data02_10.json\n",
      "data02_11.json\n",
      "data02_12.json\n",
      "data03_01.json\n",
      "data03_02.json\n",
      "data03_03.json\n",
      "data03_04.json\n",
      "data03_05.json\n",
      "data03_06.json\n",
      "data03_07.json\n",
      "data03_08.json\n",
      "data03_09.json\n",
      "data03_10.json\n",
      "data03_11.json\n",
      "data03_12.json\n",
      "data04_01.json\n",
      "data04_02.json\n",
      "data04_03.json\n",
      "data04_04.json\n",
      "data04_05.json\n",
      "data04_06.json\n",
      "data04_07.json\n",
      "data04_08.json\n",
      "data04_09.json\n",
      "data04_10.json\n",
      "data04_11.json\n",
      "data04_12.json\n",
      "data05_01.json\n",
      "data05_02.json\n",
      "data05_03.json\n",
      "data05_04.json\n",
      "data05_05.json\n",
      "data05_06.json\n",
      "data05_07.json\n",
      "data05_08.json\n",
      "data05_09.json\n",
      "data05_10.json\n",
      "data05_11.json\n",
      "data05_12.json\n",
      "data06_01.json\n",
      "data06_02.json\n",
      "data06_03.json\n",
      "data06_04.json\n",
      "data06_05.json\n",
      "data06_06.json\n",
      "data06_07.json\n",
      "data06_08.json\n",
      "data06_09.json\n",
      "data06_10.json\n",
      "data06_11.json\n",
      "data06_12.json\n",
      "data07_01.json\n",
      "data07_02.json\n",
      "data07_03.json\n",
      "data07_04.json\n",
      "data07_05.json\n",
      "data07_06.json\n",
      "data07_07.json\n",
      "data07_08.json\n",
      "data07_09.json\n",
      "data07_10.json\n",
      "data07_11.json\n",
      "data07_12.json\n",
      "data08_01.json\n",
      "data08_02.json\n",
      "data08_03.json\n",
      "data08_04.json\n",
      "data08_05.json\n",
      "data08_06.json\n",
      "data08_07.json\n",
      "data08_08.json\n",
      "data08_09.json\n",
      "data08_10.json\n",
      "data08_11.json\n",
      "data08_12.json\n",
      "data09_01.json\n",
      "data09_02.json\n",
      "data09_03.json\n",
      "data09_04.json\n",
      "data09_05.json\n",
      "data09_06.json\n",
      "data09_07.json\n",
      "data09_08.json\n",
      "data09_09.json\n",
      "data09_10.json\n",
      "data09_11.json\n",
      "data09_12.json\n",
      "data10_01.json\n",
      "data10_02.json\n",
      "data10_03.json\n",
      "data10_04.json\n",
      "data10_05.json\n",
      "data10_06.json\n",
      "data10_07.json\n",
      "data10_08.json\n",
      "data10_09.json\n",
      "data10_10.json\n",
      "data10_11.json\n",
      "data10_12.json\n",
      "data11_01.json\n",
      "data11_02.json\n",
      "data11_03.json\n",
      "data11_04.json\n",
      "data11_05.json\n",
      "data11_06.json\n",
      "data11_07.json\n",
      "data11_08.json\n",
      "data11_09.json\n",
      "data11_10.json\n",
      "data11_11.json\n",
      "data11_12.json\n",
      "data12_01.json\n",
      "data12_02.json\n",
      "data12_03.json\n",
      "data12_04.json\n",
      "data12_05.json\n",
      "data12_06.json\n",
      "data12_07.json\n",
      "data12_08.json\n",
      "data12_09.json\n",
      "data12_10.json\n",
      "data12_11.json\n",
      "data12_12.json\n",
      "data13_01.json\n",
      "data13_02.json\n",
      "data13_03.json\n",
      "data13_04.json\n",
      "data13_05.json\n",
      "data13_06.json\n",
      "data13_07.json\n",
      "data13_08.json\n",
      "data13_09.json\n",
      "data13_10.json\n",
      "data13_11.json\n",
      "data13_12.json\n",
      "data14_01.json\n",
      "data14_02.json\n",
      "data14_03.json\n",
      "data14_04.json\n",
      "data14_05.json\n",
      "data14_06.json\n",
      "data14_07.json\n",
      "data14_08.json\n",
      "data14_09.json\n",
      "data14_10.json\n",
      "data14_11.json\n",
      "data14_12.json\n",
      "data15_01.json\n",
      "data15_02.json\n",
      "data15_03.json\n",
      "data15_04.json\n",
      "data15_05.json\n",
      "data15_06.json\n",
      "data15_07.json\n",
      "data15_08.json\n",
      "data15_09.json\n",
      "data15_10.json\n",
      "data15_11.json\n",
      "data15_12.json\n",
      "data16_01.json\n",
      "data16_02.json\n",
      "data16_03.json\n",
      "data16_04.json\n",
      "data16_05.json\n",
      "data16_06.json\n",
      "data16_07.json\n",
      "data16_08.json\n",
      "data16_09.json\n",
      "data16_10.json\n",
      "data16_11.json\n",
      "data16_12.json\n",
      "data17_01.json\n",
      "data17_02.json\n",
      "data17_03.json\n",
      "data17_04.json\n",
      "data17_05.json\n",
      "data17_06.json\n",
      "data17_07.json\n",
      "data17_08.json\n",
      "data17_09.json\n",
      "data17_10.json\n",
      "data17_11.json\n",
      "data17_12.json\n",
      "data18_01.json\n",
      "data18_02.json\n",
      "data18_03.json\n",
      "data18_04.json\n",
      "data18_05.json\n",
      "data18_06.json\n",
      "data18_07.json\n",
      "data18_08.json\n",
      "data18_09.json\n",
      "data18_10.json\n",
      "data18_11.json\n",
      "data18_12.json\n",
      "data19_01.json\n",
      "data19_02.json\n",
      "data19_03.json\n",
      "data19_04.json\n",
      "data19_05.json\n",
      "data19_06.json\n",
      "data19_07.json\n",
      "data19_08.json\n",
      "data19_09.json\n",
      "data19_10.json\n",
      "data19_11.json\n",
      "data19_12.json\n",
      "data20_01.json\n",
      "data20_02.json\n",
      "data20_03.json\n",
      "data20_04.json\n",
      "data20_05.json\n",
      "data20_06.json\n",
      "data20_07.json\n",
      "data20_08.json\n",
      "data20_09.json\n",
      "data20_10.json\n",
      "data20_11.json\n",
      "data20_12.json\n",
      "data21_01.json\n",
      "data21_02.json\n",
      "data21_03.json\n",
      "data21_04.json\n",
      "data21_05.json\n",
      "data21_06.json\n",
      "data21_07.json\n",
      "data21_08.json\n",
      "data21_09.json\n",
      "data21_10.json\n",
      "data21_11.json\n",
      "data21_12.json\n",
      "data22_01.json\n",
      "data22_02.json\n",
      "data22_03.json\n",
      "data22_04.json\n",
      "data22_05.json\n",
      "data22_06.json\n",
      "data22_07.json\n",
      "data22_08.json\n",
      "data22_09.json\n",
      "data22_10.json\n",
      "data22_11.json\n",
      "data22_12.json\n",
      "data23_01.json\n",
      "data23_02.json\n",
      "data23_03.json\n",
      "data23_04.json\n",
      "data23_05.json\n",
      "data23_06.json\n",
      "data23_07.json\n",
      "data23_08.json\n",
      "data23_09.json\n",
      "data23_10.json\n",
      "data23_11.json\n",
      "data23_12.json\n",
      "data24_01.json\n",
      "data24_02.json\n",
      "data24_03.json\n",
      "data24_04.json\n",
      "data24_05.json\n",
      "data24_06.json\n",
      "data24_07.json\n",
      "data24_08.json\n",
      "data24_09.json\n",
      "data24_10.json\n",
      "data24_11.json\n",
      "data24_12.json\n",
      "data25_01.json\n",
      "data25_02.json\n",
      "data25_03.json\n",
      "data25_04.json\n",
      "data25_05.json\n",
      "data25_06.json\n",
      "data25_07.json\n",
      "data25_08.json\n",
      "data25_09.json\n",
      "data25_10.json\n",
      "data25_11.json\n",
      "data25_12.json\n",
      "data26_01.json\n",
      "data26_02.json\n",
      "data26_03.json\n",
      "data26_04.json\n",
      "data26_05.json\n",
      "data26_06.json\n",
      "data26_07.json\n",
      "data26_08.json\n",
      "data26_09.json\n",
      "data26_10.json\n",
      "data26_11.json\n",
      "data26_12.json\n",
      "data27_01.json\n",
      "data27_02.json\n",
      "data27_03.json\n",
      "data27_04.json\n",
      "data27_05.json\n",
      "data27_06.json\n",
      "data27_07.json\n",
      "data27_08.json\n",
      "data27_09.json\n",
      "data27_10.json\n",
      "data27_11.json\n",
      "data27_12.json\n",
      "data28_01.json\n",
      "data28_02.json\n",
      "data28_03.json\n",
      "data28_04.json\n",
      "data28_05.json\n",
      "data28_06.json\n",
      "data28_07.json\n",
      "data28_08.json\n",
      "data28_09.json\n",
      "data28_10.json\n",
      "data28_11.json\n",
      "data28_12.json\n",
      "data29_01.json\n",
      "data29_03.json\n",
      "data29_04.json\n",
      "data29_05.json\n",
      "data29_06.json\n",
      "data29_07.json\n",
      "data29_08.json\n",
      "data29_09.json\n",
      "data29_10.json\n",
      "data29_11.json\n",
      "data29_12.json\n",
      "data30_01.json\n",
      "data30_03.json\n",
      "data30_04.json\n",
      "data30_05.json\n",
      "data30_06.json\n",
      "data30_07.json\n",
      "data30_08.json\n",
      "data30_09.json\n",
      "data30_10.json\n",
      "data30_11.json\n",
      "data30_12.json\n",
      "data31_01.json\n",
      "data31_03.json\n",
      "data31_05.json\n",
      "data31_07.json\n",
      "data31_08.json\n",
      "data31_10.json\n",
      "data31_12.json\n"
     ]
    }
   ],
   "source": [
    "# Group data by month\n",
    "data_dir = 'data'\n",
    "files = sorted(os.listdir(data_dir))\n",
    "monthly_data = defaultdict(list)\n",
    "\n",
    "# Read data from each file and distibute it accordingly\n",
    "for file in files:\n",
    "    if file[:4] != 'data':\n",
    "        continue\n",
    "    month = int(file.split('.')[0].split('_')[1])\n",
    "    monthly_data[month].append(json.load(open(os.path.join(data_dir, file), 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each month find the maximum size for each id\n",
    "for i in range(1, 13):\n",
    "    month_data = monthly_data[i]\n",
    "    max_month_data = []\n",
    "    for j in range(len(month_data[0])):\n",
    "        absolute = [d[j]['absolute_size'] for d in month_data]\n",
    "        average = [d[j]['average_change_size'] for d in month_data]\n",
    "        if i == 1:\n",
    "            daily = [month_data[k][j]['daily_change_size'] for k in range(1, len(month_data))]\n",
    "            daily_diff = 2\n",
    "        else:\n",
    "            daily = [d[j]['daily_change_size'] for d in month_data]\n",
    "            daily_diff = 1\n",
    "        \n",
    "        max_absolute, max_absolute_day = int(np.max(absolute)), int(np.argmax(absolute)) + 1\n",
    "        max_daily, max_daily_day = int(np.max(daily)), int(np.argmax(daily)) + daily_diff\n",
    "        max_average, max_average_day = int(np.max(average)), int(np.argmax(average)) + 1\n",
    "\n",
    "        max_month_data.append({\n",
    "            'id': month_data[0][j]['id'],\n",
    "            'absolute_size': max_absolute,\n",
    "            'absolute_day': max_absolute_day,\n",
    "            'daily_change_size': max_daily,\n",
    "            'daily_change_day': max_daily_day,\n",
    "            'average_change_size': max_average,\n",
    "            'average_change_day': max_average_day\n",
    "        })\n",
    "    # Write data to file\n",
    "    json.dump(max_month_data, open(os.path.join(data_dir, f'data{i}.json'), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
