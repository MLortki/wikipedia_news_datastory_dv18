{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "\n",
    "data_file = 'data/wiki_data.pkl'\n",
    "links_file = 'data/links.tsv'\n",
    "out_dir = 'data/daily_visitors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, read visit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>01/01</th>\n",
       "      <th>02/01</th>\n",
       "      <th>03/01</th>\n",
       "      <th>04/01</th>\n",
       "      <th>05/01</th>\n",
       "      <th>06/01</th>\n",
       "      <th>07/01</th>\n",
       "      <th>08/01</th>\n",
       "      <th>09/01</th>\n",
       "      <th>...</th>\n",
       "      <th>22/12</th>\n",
       "      <th>23/12</th>\n",
       "      <th>24/12</th>\n",
       "      <th>25/12</th>\n",
       "      <th>26/12</th>\n",
       "      <th>27/12</th>\n",
       "      <th>28/12</th>\n",
       "      <th>29/12</th>\n",
       "      <th>30/12</th>\n",
       "      <th>31/12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áedán mac Gabráin</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Åland</td>\n",
       "      <td>136</td>\n",
       "      <td>184</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>209</td>\n",
       "      <td>168</td>\n",
       "      <td>131</td>\n",
       "      <td>157</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>109</td>\n",
       "      <td>123</td>\n",
       "      <td>112</td>\n",
       "      <td>141</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Édouard Manet</td>\n",
       "      <td>703</td>\n",
       "      <td>895</td>\n",
       "      <td>951</td>\n",
       "      <td>1081</td>\n",
       "      <td>1047</td>\n",
       "      <td>977</td>\n",
       "      <td>984</td>\n",
       "      <td>1121</td>\n",
       "      <td>1221</td>\n",
       "      <td>...</td>\n",
       "      <td>553</td>\n",
       "      <td>643</td>\n",
       "      <td>638</td>\n",
       "      <td>745</td>\n",
       "      <td>793</td>\n",
       "      <td>773</td>\n",
       "      <td>763</td>\n",
       "      <td>725</td>\n",
       "      <td>737</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Éire</td>\n",
       "      <td>320</td>\n",
       "      <td>368</td>\n",
       "      <td>396</td>\n",
       "      <td>378</td>\n",
       "      <td>414</td>\n",
       "      <td>438</td>\n",
       "      <td>354</td>\n",
       "      <td>394</td>\n",
       "      <td>405</td>\n",
       "      <td>...</td>\n",
       "      <td>364</td>\n",
       "      <td>289</td>\n",
       "      <td>326</td>\n",
       "      <td>372</td>\n",
       "      <td>360</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>368</td>\n",
       "      <td>346</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Óengus I of the Picts</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article  01/01  02/01  03/01  04/01  05/01  06/01  07/01  \\\n",
       "0      Áedán mac Gabráin     35     42     63     46     70     54     43   \n",
       "1                  Åland    136    184    162    163    209    168    131   \n",
       "2          Édouard Manet    703    895    951   1081   1047    977    984   \n",
       "3                   Éire    320    368    396    378    414    438    354   \n",
       "4  Óengus I of the Picts     28     32     22     18     33     18     22   \n",
       "\n",
       "   08/01  09/01  ...    22/12  23/12  24/12  25/12  26/12  27/12  28/12  \\\n",
       "0     48     44  ...       28     38     26     43     54     44     36   \n",
       "1    157    203  ...      110     95     95    109    123    112    141   \n",
       "2   1121   1221  ...      553    643    638    745    793    773    763   \n",
       "3    394    405  ...      364    289    326    372    360    389    389   \n",
       "4     32     25  ...       21     26     12     34     47     26     24   \n",
       "\n",
       "   29/12  30/12  31/12  \n",
       "0     45     29     84  \n",
       "1    135    122     99  \n",
       "2    725    737    630  \n",
       "3    368    346    390  \n",
       "4     23     35     28  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_data(file):\n",
    "    data = pkl.load(open(file, 'rb'))\n",
    "\n",
    "    data = data.drop('categories', axis=1)\n",
    "    traffic = data['traffic']\n",
    "    \n",
    "    # Remove data for which there are not enough days\n",
    "    day_count = traffic.apply(lambda x: len(x))\n",
    "    traffic = traffic[day_count == 365]\n",
    "    \n",
    "    # Separate data by days\n",
    "    day_series = {}\n",
    "    for i in range(365):\n",
    "        day = traffic.iloc[0][i][1].split('-')\n",
    "        day[2] = day[2].split('T')[0]\n",
    "        day = f'{day[2]}/{day[1]}'\n",
    "        day_series[day] = traffic.apply(lambda x: x[i][0])\n",
    "    \n",
    "    # Add visit by day columns to the dataframe\n",
    "    data = data[day_count == 365]\n",
    "    data = pd.concat([data, pd.DataFrame(day_series)], axis=1)\n",
    "    data = data.drop('traffic', axis=1)    \n",
    "    return data\n",
    "\n",
    "\n",
    "visit_data = read_data(data_file)\n",
    "display(visit_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the links between the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read hyperlinks dataset\n",
    "links = pd.read_csv('data/links.tsv', \n",
    "                    sep='\\t', \n",
    "                    encoding='utf-8', \n",
    "                    engine='python', \n",
    "                    header=None, \n",
    "                    comment='#',\n",
    "                    names=['source', 'target'])\n",
    "\n",
    "links['source'] = links['source'].apply(lambda s: urllib.parse.unquote(s))\n",
    "links['target'] = links['target'].apply(lambda s: urllib.parse.unquote(s))\n",
    "\n",
    "display(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29326</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Binoculars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29327</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Clone_Wars_(Star_Wars)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29328</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Darth_Vader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29329</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Dutch_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29330</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Frankenstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29331</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>German_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29332</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29333</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>King_Arthur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29334</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Natalie_Portman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29335</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Obi-Wan_Kenobi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Star_Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Star_Wars_Episode_IV__A_New_Hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Stargate_SG-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>Darth_Vader</td>\n",
       "      <td>Superman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                            target\n",
       "29326  Darth_Vader                        Binoculars\n",
       "29327  Darth_Vader            Clone_Wars_(Star_Wars)\n",
       "29328  Darth_Vader                       Darth_Vader\n",
       "29329  Darth_Vader                    Dutch_language\n",
       "29330  Darth_Vader                      Frankenstein\n",
       "29331  Darth_Vader                   German_language\n",
       "29332  Darth_Vader                             Japan\n",
       "29333  Darth_Vader                       King_Arthur\n",
       "29334  Darth_Vader                   Natalie_Portman\n",
       "29335  Darth_Vader                    Obi-Wan_Kenobi\n",
       "29336  Darth_Vader                         Star_Wars\n",
       "29337  Darth_Vader  Star_Wars_Episode_IV__A_New_Hope\n",
       "29338  Darth_Vader                     Stargate_SG-1\n",
       "29339  Darth_Vader                          Superman"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[links['source'] == 'Darth_Vader']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start generating the data. We will first generate the edges, which are common for all the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mapping between article name and its ID for fast retrieval\n",
    "article_dict = {}\n",
    "for i in range(len(visit_data)):\n",
    "    article_dict[visit_data.iloc[i].article] = f'n{i}'\n",
    "\n",
    "edges = []\n",
    "cnt = 0\n",
    "for i in range(len(links)):\n",
    "    source = links.iloc[i].source.replace('_', ' ')\n",
    "    target = links.iloc[i].target.replace('_', ' ')\n",
    "    if source in article_dict and target in article_dict:\n",
    "        edge = {\n",
    "            'id': f'e{cnt}',\n",
    "            'source': article_dict[source],\n",
    "            'target': article_dict[target],\n",
    "            'type': 'arrow'\n",
    "        }\n",
    "        cnt += 1\n",
    "        edges.append(edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the node data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_nodes = defaultdict(list)\n",
    "for i in range(len(visit_data)):\n",
    "    for day in visit_data.columns[1:]:\n",
    "        node = {\n",
    "            'id': article_dict[visit_data.iloc[i].article],\n",
    "            'label': visit_data.iloc[i].article,\n",
    "            'size': visit_data[day].iloc[i]\n",
    "        }\n",
    "        daily_nodes[day].append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the edge and the node data in pickle files\n",
    "pkl.dump(edges, open('data/edges.pkl', 'wb'))\n",
    "pkl.dump(daily_nodes, open('data/nodes.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/edges.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3fa5eb377f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/edges.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/nodes.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/edges.pkl'"
     ]
    }
   ],
   "source": [
    "edges = pkl.load(open('data/edges.pkl', 'rb'))\n",
    "nodes = pkl.load(open('data/nodes.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116230"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = {\n",
    "    'nodes': nodes['01/01'],\n",
    "    'edges': edges\n",
    "}\n",
    "sample_data['nodes'] = list(map(lambda x: {\n",
    "    'id': x['id'],\n",
    "    'label': x['label'],\n",
    "    'size': int(x['size'])\n",
    "}, sample_data['nodes']))\n",
    "\n",
    "# json.dump(sample_data, open('sample_data.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group data by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by month\n",
    "data_dir = 'data'\n",
    "files = sorted(os.listdir(data_dir))\n",
    "monthly_data = defaultdict(list)\n",
    "\n",
    "# Read data from each file and distibute it accordingly\n",
    "for file in files:\n",
    "    if file[:4] != 'data' or file.find('_') == -1:\n",
    "        continue\n",
    "    month = int(file.split('.')[0].split('_')[1])\n",
    "    monthly_data[month].append(json.load(open(os.path.join(data_dir, file), 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each month find the maximum size for each id\n",
    "for i in range(1, 13):\n",
    "    month_data = monthly_data[i]\n",
    "    max_month_data = []\n",
    "    for j in range(len(month_data[0])):\n",
    "        absolute = [d[j]['absolute_size'] for d in month_data]\n",
    "        average = [d[j]['average_change_size'] for d in month_data]\n",
    "        if i == 1:\n",
    "            daily = [month_data[k][j]['daily_change_size'] for k in range(1, len(month_data))]\n",
    "            daily_diff = 2\n",
    "        else:\n",
    "            daily = [d[j]['daily_change_size'] for d in month_data]\n",
    "            daily_diff = 1\n",
    "        \n",
    "        max_absolute, max_absolute_day = int(np.max(absolute)), int(np.argmax(absolute)) + 1\n",
    "        max_daily, max_daily_day = int(np.max(daily)), int(np.argmax(daily)) + daily_diff\n",
    "        max_average, max_average_day = int(np.max(average)), int(np.argmax(average)) + 1\n",
    "\n",
    "        max_month_data.append({\n",
    "            'id': month_data[0][j]['id'],\n",
    "            'absolute_size': max_absolute,\n",
    "            'absolute_day': max_absolute_day,\n",
    "            'daily_change_size': max_daily,\n",
    "            'daily_change_day': max_daily_day,\n",
    "            'average_change_size': max_average,\n",
    "            'average_change_day': max_average_day,\n",
    "            'all_visits': absolute\n",
    "        })\n",
    "    # Write data to file\n",
    "    json.dump(max_month_data, open(os.path.join(data_dir, f'data{i}.json'), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ids to labels\n",
    "nodes = json.load(open(os.path.join(data_dir, 'nodes.json'), 'r'))\n",
    "id_to_label = {}\n",
    "for node in nodes:\n",
    "    id_to_label[node['id']] = node['label']\n",
    "\n",
    "# Select the most interesting articles for each month\n",
    "NO_ARTICLES = 30\n",
    "articles = {}\n",
    "for i in range(1, 13):\n",
    "    json_data = json.load(open(os.path.join(data_dir, f'data{i}.json'), 'r'))\n",
    "    data = [[d['daily_change_size'], id_to_label[d['id']], d['id'], d['daily_change_day']] for d in json_data]\n",
    "    data = sorted(data, reverse=True)\n",
    "    articles[i] = data[:NO_ARTICLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the articles\n",
    "news_data = ''\n",
    "for month in articles:\n",
    "    for art in articles[month]:\n",
    "        news_data += f'{art[1]} {art[3]}/{month}\\n'\n",
    "        \n",
    "with open('articles.txt', 'w') as f:\n",
    "    f.write(news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get category visit counts each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "categories = os.path.join(data_dir, 'article_subject.csv')\n",
    "\n",
    "# Read categories file in a dataframe\n",
    "categories_df = pd.read_csv(categories).drop('Unnamed: 0', axis=1)\n",
    "categories_df['name'] = categories_df['name'].apply(lambda s: urllib.parse.unquote(s))\n",
    "categories_df['name'] = categories_df['name'].apply(lambda x: x.replace('__', ': ').replace('_', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe elements\n",
    "nodes_data = json.load(open(os.path.join(data_dir, 'nodes.json'), 'r'))\n",
    "nodes_dict = {}\n",
    "for node in nodes_data:\n",
    "    name = node['label']\n",
    "    if categories_df[categories_df['name'] == name].categories.shape[0] > 0:\n",
    "        nodes_dict[name] = [node['id'], categories_df[categories_df['name'] == name].categories.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each category the number of visits per day\n",
    "day_visits = {}\n",
    "keys = list(nodes_dict.keys())\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.find('data') == -1 or file.find('_') == -1:\n",
    "        continue\n",
    "    day = file[4:9]\n",
    "    data = json.load(open(os.path.join(data_dir, file), 'r'))\n",
    "    day_dict = defaultdict(int)\n",
    "    ind_data, ind_dict = 0, 0    \n",
    "    while ind_data < len(data) - 1 and ind_dict < len(keys) - 1:\n",
    "        if data[ind_data]['id'] == nodes_dict[keys[ind_dict]][0]:\n",
    "            ind_dict += 1\n",
    "            visits = data[ind_data]['absolute_size']\n",
    "            cat_list = ast.literal_eval(nodes_dict[keys[ind_dict]][1])\n",
    "            for category in cat_list:\n",
    "                day_dict[category] += visits\n",
    "        ind_data += 1\n",
    "    day_visits[day] = day_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to normal dictionary\n",
    "for key in day_visits:\n",
    "    day_visits[key] = dict(day_visits[key])\n",
    "\n",
    "# Write data to json file\n",
    "with open(os.path.join(data_dir, 'categories.json'), 'w') as f:\n",
    "    json.dump(day_visits, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
